{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "retrainingarcface6/11/1230h.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1tApvBIYmERYn9aQaP_16Sa07O4FApABh",
      "authorship_tag": "ABX9TyMG7b9GwdiksBwrbsBZV5R0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d8611737b60c4ba6bf1e1d362a2d447f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_14e2a9062ff147f3bb879d3a1f4e40ad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f795f936e3194b04b9049c9adc6df472",
              "IPY_MODEL_ced0ac04781440b2b79dd9090f40a0fc"
            ]
          }
        },
        "14e2a9062ff147f3bb879d3a1f4e40ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f795f936e3194b04b9049c9adc6df472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_253ca39493814b299dde903ab8bb66e1",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 111898327,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 111898327,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d59730445d364588a98beca33ee038d7"
          }
        },
        "ced0ac04781440b2b79dd9090f40a0fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f42e09625d684ea2a7d6e8edaf4b7f87",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 107M/107M [00:01&lt;00:00, 73.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d4702e1b144430390904885ca048b27"
          }
        },
        "253ca39493814b299dde903ab8bb66e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d59730445d364588a98beca33ee038d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f42e09625d684ea2a7d6e8edaf4b7f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d4702e1b144430390904885ca048b27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Quillbolt/colabnotebook/blob/main/retrainingarcface6_11_1230h.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_kYU7zl4ieI"
      },
      "source": [
        "!pip install facenet-pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aBGgQ2s4ibG"
      },
      "source": [
        "\n",
        "batch_size = 32\n",
        "epochs = 8\n",
        "workers = 0 if os.name == 'nt' else 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoDqobhf4iUO"
      },
      "source": [
        "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization, training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-65jjt3ZwRd7"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPJPSY22zugN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9660db9-c740-4119-dfee-d93efcb43b08"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Running on device: {}'.format(device))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eREQ6HY5VAT"
      },
      "source": [
        "mtcnn = MTCNN(\n",
        "    image_size=160, margin=0, min_face_size=20,\n",
        "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
        "    device=device\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC4U86ka5mod"
      },
      "source": [
        "data_dir = '/content/drive/My Drive/godeyedata/train'\n",
        "dataset = datasets.ImageFolder(data_dir, transform=transforms.Resize((512, 512)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTQ58sWY3OWt"
      },
      "source": [
        "traindir = '/content/drive/My Drive/godeyedata/train'\n",
        "valdir = '/content/drive/My Drive/godeyedata/val'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXvjOoK821z2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "8d810c89-dc60-4217-dc42-a8eaa4407fe2"
      },
      "source": [
        "train_dataset = datasets.ImageFolder(\n",
        "    traindir,\n",
        "    transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "          ]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-44ef8838ce3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomHorizontalFlip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mnormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m           ]))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'normalize' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-hbLdRE3pyW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "9abff199-ab28-408b-9f68-8ea30254b67e"
      },
      "source": [
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    num_workers=workers,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=training.collate_pil\n",
        ")\n",
        "\n",
        "for i, (x, y) in enumerate(loader):\n",
        "    mtcnn(x, save_path=y)\n",
        "    print('\\rBatch {} of {}'.format(i + 1, len(loader)), end='')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-6206b18b1d08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmtcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\rBatch {} of {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/facenet_pytorch/models/mtcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img, save_path, return_prob)\u001b[0m\n\u001b[1;32m    263\u001b[0m             )\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# Extract faces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/facenet_pytorch/models/mtcnn.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, img, batch_boxes, save_path)\u001b[0m\n\u001b[1;32m    486\u001b[0m                     \u001b[0mface_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m                 \u001b[0mface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_process\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                     \u001b[0mface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfixed_image_standardization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/facenet_pytorch/models/utils/detect_face.py\u001b[0m in \u001b[0;36mextract_face\u001b[0;34m(img, box, image_size, margin, save_path)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0msave_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/posixpath.py\u001b[0m in \u001b[0;36mdirname\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;34m\"\"\"Returns the directory component of a pathname\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not int"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNwT437V28-d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "99f685f2-e38b-4524-90c4-303e2fd72e58"
      },
      "source": [
        "val_loader = torch.utils.data.DataLoader(\n",
        "    datasets.ImageFolder(valdir, transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-2a43bfcda26a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m val_loader = torch.utils.data.DataLoader(\n\u001b[0;32m----> 2\u001b[0;31m     datasets.ImageFolder(valdir, transforms.Compose([\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCenterCrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'valdir' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf5TeX_c2Qdl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "85b43b91-83a9-41b3-adb2-b5e3f22d2cd5"
      },
      "source": [
        "model  = torch.load('/content/drive/My Drive/Face-Recognition/work_space/model/model_ir_se50.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnpicklingError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-fe88766846a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Face-Recognition/work_space/model/model_ir_se50.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    593\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \"functionality.\")\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m     \u001b[0mmagic_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmagic_number\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mMAGIC_NUMBER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid magic number; corrupt file?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, 'v'."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eApejqbgE3e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "d8611737b60c4ba6bf1e1d362a2d447f",
            "14e2a9062ff147f3bb879d3a1f4e40ad",
            "f795f936e3194b04b9049c9adc6df472",
            "ced0ac04781440b2b79dd9090f40a0fc",
            "253ca39493814b299dde903ab8bb66e1",
            "d59730445d364588a98beca33ee038d7",
            "f42e09625d684ea2a7d6e8edaf4b7f87",
            "0d4702e1b144430390904885ca048b27"
          ]
        },
        "outputId": "84054c03-5104-44f2-da32-ff2d1b7ff4e2"
      },
      "source": [
        "\n",
        "resnet = InceptionResnetV1(\n",
        "    classify=True,\n",
        "    pretrained='vggface2',\n",
        "    num_classes=len(dataset.class_to_idx)\n",
        ").to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8611737b60c4ba6bf1e1d362a2d447f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=111898327.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7aw-5uME8xA"
      },
      "source": [
        "trans = transforms.Compose([\n",
        "    np.float32,\n",
        "    transforms.ToTensor()\n",
        "    \n",
        "])\n",
        "dataset = datasets.ImageFolder(data_dir ,  transform=trans)\n",
        "img_inds = np.arange(len(dataset))\n",
        "np.random.shuffle(img_inds)\n",
        "train_inds = img_inds[:int(0.8 * len(img_inds))]\n",
        "val_inds = img_inds[int(0.8 * len(img_inds)):]\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset,\n",
        "    num_workers=workers,\n",
        "    batch_size=batch_size,\n",
        "    sampler=SubsetRandomSampler(train_inds)\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    dataset,\n",
        "    num_workers=workers,\n",
        "    batch_size=batch_size,\n",
        "    sampler=SubsetRandomSampler(val_inds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U47lK7llE3W6"
      },
      "source": [
        "def adjust_learning_rate(optimizer, gamma, epoch, step_index, iteration, epoch_size):\n",
        "    \"\"\"Sets the learning rate\n",
        "    # Adapted from PyTorch Imagenet example:\n",
        "    # https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
        "    \"\"\"\n",
        "    warmup_epoch = -1\n",
        "    if epoch <= warmup_epoch:\n",
        "        lr = 1e-6 + (initial_lr-1e-6) * iteration / (epoch_size * warmup_epoch)\n",
        "    else:\n",
        "        lr = initial_lr * (gamma ** (step_index))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "    return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l7LG9vu4Bz9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "ae87a6d0-4059-44c0-ea99-49d3951f00bd"
      },
      "source": [
        "optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
        "scheduler = MultiStepLR(optimizer, [5, 10])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-c9780648c730>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'resnet' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdIFg-E942hK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "56340fe7-7f88-48d1-a694-dfc598d4a62c"
      },
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "metrics = {\n",
        "    'fps': training.BatchTimer(),\n",
        "    'acc': training.accuracy}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-c5e0a47249e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m metrics = {\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;34m'fps'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     'acc': training.accuracy}\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZB-aVcfFVby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "847a09ec-75e6-432e-9622-ed6ffc6ab049"
      },
      "source": [
        "writer = SummaryWriter()\n",
        "writer.iteration, writer.interval = 0, 10\n",
        "\n",
        "print('\\n\\nInitial')\n",
        "print('-' * 10)\n",
        "resnet.eval()\n",
        "training.pass_epoch(\n",
        "    resnet, loss_fn, val_loader,\n",
        "    batch_metrics=metrics, show_running=True, device=device,\n",
        "    writer=writer\n",
        ")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
        "    print('-' * 10)\n",
        "\n",
        "    resnet.train()\n",
        "    training.pass_epoch(\n",
        "        resnet, loss_fn, train_loader, optimizer, scheduler,\n",
        "        batch_metrics=metrics, show_running=True, device=device,\n",
        "        writer=writer\n",
        "    )\n",
        "\n",
        "    resnet.eval()\n",
        "    training.pass_epoch(\n",
        "        resnet, loss_fn, val_loader,\n",
        "        batch_metrics=metrics, show_running=True, device=device,\n",
        "        writer=writer\n",
        "    )\n",
        "\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Initial\n",
            "----------\n",
            "Valid |     1/1    | loss:    1.9211 | fps:    0.4721 | acc:    0.0769   \n",
            "\n",
            "Epoch 1/8\n",
            "----------\n",
            "Train |     2/2    | loss:    1.5732 | fps:   64.8894 | acc:    0.3577   \n",
            "Valid |     1/1    | loss:    0.6259 | fps:   23.2615 | acc:    0.7692   \n",
            "\n",
            "Epoch 2/8\n",
            "----------\n",
            "Train |     2/2    | loss:    0.1320 | fps:   96.0022 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:   13.0053 | fps:   23.7348 | acc:    0.3077   \n",
            "\n",
            "Epoch 3/8\n",
            "----------\n",
            "Train |     2/2    | loss:    0.0278 | fps:   96.5136 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    5.6494 | fps:   23.3826 | acc:    0.3846   \n",
            "\n",
            "Epoch 4/8\n",
            "----------\n",
            "Train |     2/2    | loss:    0.0090 | fps:   96.4181 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.8263 | fps:   23.4406 | acc:    0.7692   \n",
            "\n",
            "Epoch 5/8\n",
            "----------\n",
            "Train |     2/2    | loss:    0.0086 | fps:   96.2859 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.7685 | fps:   23.8987 | acc:    0.7692   \n",
            "\n",
            "Epoch 6/8\n",
            "----------\n",
            "Train |     2/2    | loss:    0.0133 | fps:   95.4487 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.4598 | fps:   23.1968 | acc:    0.8462   \n",
            "\n",
            "Epoch 7/8\n",
            "----------\n",
            "Train |     2/2    | loss:    0.0062 | fps:   96.4901 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.2668 | fps:   23.8502 | acc:    0.9231   \n",
            "\n",
            "Epoch 8/8\n",
            "----------\n",
            "Train |     2/2    | loss:    0.0040 | fps:   95.5654 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.1913 | fps:   23.5013 | acc:    0.9231   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTZxi0HpT2s3"
      },
      "source": [
        "def collate_fn(x):\n",
        "    return x[0]\n",
        "\n",
        "dataset = datasets.ImageFolder('/content/drive/My Drive/godeyedata/test')\n",
        "dataset.idx_to_class = {i:c for c, i in dataset.class_to_idx.items()}\n",
        "loader = DataLoader(dataset, collate_fn=collate_fn, num_workers=workers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYTj9iFrVi5b"
      },
      "source": [
        "resnet=torch.load('/content/drive/My Drive/Pytorch_Retinaface/weights/Resnet50_Final.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPXwCTRQZCf-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e4e8bb4-6bfa-447d-e11c-26d170cffbf2"
      },
      "source": [
        "\n",
        "aligned = []\n",
        "names = []\n",
        "for x, y in loader:\n",
        "    x_aligned, prob = mtcnn(x, return_prob=True)\n",
        "    if x_aligned is not None:\n",
        "        print('Face detected with probability: {:8f}'.format(prob))\n",
        "        aligned.append(x_aligned)\n",
        "        names.append(dataset.idx_to_class[y])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Face detected with probability: 0.999999\n",
            "Face detected with probability: 0.999987\n",
            "Face detected with probability: 0.999994\n",
            "Face detected with probability: 0.999954\n",
            "Face detected with probability: 0.999987\n",
            "Face detected with probability: 0.999975\n",
            "Face detected with probability: 0.997339\n",
            "Face detected with probability: 0.999648\n",
            "Face detected with probability: 0.999966\n",
            "Face detected with probability: 0.999921\n",
            "Face detected with probability: 0.999996\n",
            "Face detected with probability: 0.999995\n",
            "Face detected with probability: 1.000000\n",
            "Face detected with probability: 1.000000\n",
            "Face detected with probability: 1.000000\n",
            "Face detected with probability: 1.000000\n",
            "Face detected with probability: 0.999994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY9PD8c-brYi"
      },
      "source": [
        "aligned = torch.stack(aligned).to(device)\n",
        "embeddings = resnet(aligned).detach().cpu()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAI7iRwFbvk_"
      },
      "source": [
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZK3tCsKbufo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5343789-4fa0-4302-ceaf-63e38f6e946c"
      },
      "source": [
        "dists = [[(e1 - e2).norm().item() for e2 in embeddings] for e1 in embeddings]\n",
        "print(pd.DataFrame(dists, columns=names, index=names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                     Huỳnh Tuấn Minh - MT-014  ...  Trần Tiến Hòa-MT-002\n",
            "Huỳnh Tuấn Minh - MT-014                             0.000000  ...                   2.754488\n",
            "Huỳnh Tuấn Minh - MT-014                             2.513082  ...                   2.957537\n",
            "Huỳnh Tuấn Minh - MT-014                             1.811291  ...                   3.006946\n",
            "Huỳnh Tuấn Minh - MT-014                             1.522675  ...                   2.806876\n",
            "Huỳnh Tuấn Minh - MT-014                             2.772112  ...                   3.619390\n",
            "MT - 009 Đỗ Văn Trường - done                     1.787390  ...                   2.199817\n",
            "MT - 009 Đỗ Văn Trường - done                     2.923374  ...                   2.325509\n",
            "MT - 009 Đỗ Văn Trường - done                     1.925269  ...                   2.393872\n",
            "Nguyễn Duy Khánh-MT-013                              2.162966  ...                   2.920080\n",
            "Nguyễn Hoàng Đức - MT-006                          2.458723  ...                   3.457788\n",
            "Nguyễn Hoàng Đức - MT-006                          3.057471  ...                   3.824253\n",
            "Nguyễn Quang Huy-MT-008                               2.353424  ...                   2.675400\n",
            "Nguyễn Đức Điệp-MT-004                            1.418013  ...                   2.809307\n",
            "Nguyễn Đức Điệp-MT-004                            1.417273  ...                   3.323160\n",
            "Trần Tiến Hòa-MT-002                               2.883053  ...                   1.834605\n",
            "Trần Tiến Hòa-MT-002                               3.102407  ...                   1.037857\n",
            "Trần Tiến Hòa-MT-002                               2.754488  ...                   0.000000\n",
            "\n",
            "[17 rows x 17 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}